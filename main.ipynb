{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e169a0",
   "metadata": {},
   "source": [
    "## ⚠️ Data Leakage Prevention\n",
    "\n",
    "**Changes Made to Prevent Data Leakage:**\n",
    "\n",
    "1. **❌ NO Augmented Data Used**\n",
    "   - Previously: Mixed original and augmented data, then split → augmented versions of same image in train/test\n",
    "   - Now: Uses ONLY original images from Dataset 1\n",
    "\n",
    "2. **✅ Proper Dataset 1 Splitting**\n",
    "   - Previously: All DS1 added to training, then tried to split same data for testing\n",
    "   - Now: Split DS1 into train/val/test BEFORE any usage (70%/15%/15%)\n",
    "\n",
    "3. **✅ Separate Validation Set**\n",
    "   - Previously: Only DS2 validation, no DS1 validation\n",
    "   - Now: Both DS1 and DS2 have validation sets\n",
    "\n",
    "4. **✅ No Overlapping Data**\n",
    "   - Train, validation, and test sets are completely separate\n",
    "   - Each image appears in exactly ONE split\n",
    "\n",
    "5. **⚠️ Dataset 2 Note**\n",
    "   - Dataset 2 uses pre-split folders (Training/Validation/Testing)\n",
    "   - Assumes the folder structure has no duplicate images across splits\n",
    "   - If uncertain, verify no overlapping images between folders\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4ce29",
   "metadata": {},
   "source": [
    "# Dual-Head Oral Pathology Classifier\n",
    "## Flat Multi-Task Learning (Joint Learning)\n",
    "\n",
    "This notebook implements a computer vision system to analyze oral lesions using two distinct datasets.\n",
    "\n",
    "**Architecture:** Shared Backbone with Two Independent Parallel Heads\n",
    "\n",
    "- **Head 1 (Binary):** Is it Malignant or Benign?\n",
    "- **Head 2 (Multi-Class):** What is the specific subtype?\n",
    "\n",
    "**Datasets:**\n",
    "- **Dataset 1 (DS1):** Labeled as Malignant or Benign only\n",
    "- **Dataset 2 (DS2):** Labeled with specific pathology types (MC, OC, CaS, CoS, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef4ff4",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5f0a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2026.1.4)\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.12.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.13.0.90)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.6.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for Google Colab\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install timm\n",
    "!pip install albumentations\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib seaborn\n",
    "!pip install tqdm\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa91cd13",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3793592510.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e489ad2",
   "metadata": {},
   "source": [
    "## 2. Dataset Paths Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64257406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths (Google Drive)\n",
    "BASE_PATH = '/content/drive/MyDrive/dataset'\n",
    "\n",
    "# Dataset 1 Paths (Binary: Malignant/Benign)\n",
    "DS1_ORIGINAL_BENIGN = os.path.join(BASE_PATH, 'Dataset 1', 'original_data', 'benign_lesions')\n",
    "DS1_ORIGINAL_MALIGNANT = os.path.join(BASE_PATH, 'Dataset 1', 'original_data', 'malignant_lesions')\n",
    "DS1_AUGMENTED_BENIGN = os.path.join(BASE_PATH, 'Dataset 1', 'augmented_data', 'augmented_benign')\n",
    "DS1_AUGMENTED_MALIGNANT = os.path.join(BASE_PATH, 'Dataset 1', 'augmented_data', 'augmented_malignant')\n",
    "\n",
    "# Dataset 2 Paths (Multi-class subtypes)\n",
    "# Note: There's a space after 'Dataset 2' in the folder name\n",
    "DS2_TRAINING = os.path.join(BASE_PATH, 'Dataset 2 ', 'Training')\n",
    "DS2_VALIDATION = os.path.join(BASE_PATH, 'Dataset 2 ', 'Validation')\n",
    "DS2_TESTING = os.path.join(BASE_PATH, 'Dataset 2 ', 'Testing')\n",
    "\n",
    "# Dataset 2 class names (subtypes)\n",
    "DS2_CLASSES = ['CaS', 'CoS', 'Gum', 'MC', 'OC', 'OLP', 'OT']\n",
    "\n",
    "# Define which DS2 classes are considered Malignant for Head 1\n",
    "# MC (Mucosal Cancer), OC (Oral Cancer), CaS (Cancer Squamous) are Malignant\n",
    "MALIGNANT_SUBTYPES = ['MC', 'OC', 'CaS']\n",
    "\n",
    "print(f\"DS2 Classes: {DS2_CLASSES}\")\n",
    "print(f\"Malignant Subtypes: {MALIGNANT_SUBTYPES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify paths exist\n",
    "paths_to_check = [\n",
    "    DS1_ORIGINAL_BENIGN, DS1_ORIGINAL_MALIGNANT,\n",
    "    DS1_AUGMENTED_BENIGN, DS1_AUGMENTED_MALIGNANT,\n",
    "    DS2_TRAINING, DS2_VALIDATION, DS2_TESTING\n",
    "]\n",
    "\n",
    "for path in paths_to_check:\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d393485",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in Dataset 1\n",
    "def count_images(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        return 0\n",
    "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tif', '*.tiff']\n",
    "    count = 0\n",
    "    for ext in extensions:\n",
    "        count += len(glob(os.path.join(folder, ext)))\n",
    "        count += len(glob(os.path.join(folder, ext.upper())))\n",
    "    return count\n",
    "\n",
    "print(\"=== Dataset 1 Statistics ===\")\n",
    "ds1_stats = {\n",
    "    'Original Benign': count_images(DS1_ORIGINAL_BENIGN),\n",
    "    'Original Malignant': count_images(DS1_ORIGINAL_MALIGNANT),\n",
    "    'Augmented Benign': count_images(DS1_AUGMENTED_BENIGN),\n",
    "    'Augmented Malignant': count_images(DS1_AUGMENTED_MALIGNANT)\n",
    "}\n",
    "for k, v in ds1_stats.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"\\n  Total DS1: {sum(ds1_stats.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b31f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in Dataset 2\n",
    "print(\"=== Dataset 2 Statistics ===\")\n",
    "\n",
    "for split_name, split_path in [('Training', DS2_TRAINING), ('Validation', DS2_VALIDATION), ('Testing', DS2_TESTING)]:\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    total = 0\n",
    "    for cls in DS2_CLASSES:\n",
    "        cls_path = os.path.join(split_path, cls)\n",
    "        count = count_images(cls_path)\n",
    "        total += count\n",
    "        malignant_marker = \"*\" if cls in MALIGNANT_SUBTYPES else \" \"\n",
    "        print(f\"  {malignant_marker} {cls}: {count}\")\n",
    "    print(f\"  Total: {total}\")\n",
    "\n",
    "print(\"\\n* = Malignant subtype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097f5c1",
   "metadata": {},
   "source": [
    "## 4. Custom Dataset Class (Union Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OralPathologyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Union Dataset for Dual-Head Multi-Task Learning.\n",
    "    \n",
    "    Handles both Dataset 1 (binary only) and Dataset 2 (with subtypes).\n",
    "    \n",
    "    Labels:\n",
    "        - label_head1 (binary): 0 = Benign, 1 = Malignant\n",
    "        - label_head2 (subtype): 0 to N-1 for DS2, -1 for DS1 (ignored)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels_binary, labels_subtype, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_paths: List of image file paths\n",
    "            labels_binary: List of binary labels (0=Benign, 1=Malignant)\n",
    "            labels_subtype: List of subtype labels (0 to N-1, or -1 to ignore)\n",
    "            transform: Optional transforms to apply\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.labels_binary = labels_binary\n",
    "        self.labels_subtype = labels_subtype\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get labels\n",
    "        label_binary = self.labels_binary[idx]\n",
    "        label_subtype = self.labels_subtype[idx]\n",
    "        \n",
    "        return image, label_binary, label_subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439bb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(folder):\n",
    "    \"\"\"Get all image files from a folder.\"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        return []\n",
    "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tif', '*.tiff']\n",
    "    files = []\n",
    "    for ext in extensions:\n",
    "        files.extend(glob(os.path.join(folder, ext)))\n",
    "        files.extend(glob(os.path.join(folder, ext.upper())))\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_dataset1_split(split='train', test_size=0.15, val_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Load Dataset 1 (Binary labels only) with proper train/val/test split.\n",
    "    ONLY uses original data (NO augmented data to prevent leakage).\n",
    "    \n",
    "    Args:\n",
    "        split: 'train', 'val', or 'test'\n",
    "        test_size: Proportion for test set\n",
    "        val_size: Proportion for validation set\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        image_paths, labels_binary, labels_subtype (-1 for all)\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Load ONLY original data (no augmented)\n",
    "    benign_paths = get_image_files(DS1_ORIGINAL_BENIGN)\n",
    "    malignant_paths = get_image_files(DS1_ORIGINAL_MALIGNANT)\n",
    "    \n",
    "    # Combine paths and create labels\n",
    "    all_paths = benign_paths + malignant_paths\n",
    "    all_binary = [0] * len(benign_paths) + [1] * len(malignant_paths)\n",
    "    all_subtype = [-1] * len(all_paths)  # No subtype for DS1\n",
    "    \n",
    "    # First split: separate test set\n",
    "    temp_paths, test_paths, temp_binary, test_binary, temp_subtype, test_subtype = train_test_split(\n",
    "        all_paths, all_binary, all_subtype,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=all_binary\n",
    "    )\n",
    "    \n",
    "    # Second split: separate train and validation from remaining data\n",
    "    val_size_adjusted = val_size / (1 - test_size)  # Adjust val size\n",
    "    train_paths, val_paths, train_binary, val_binary, train_subtype, val_subtype = train_test_split(\n",
    "        temp_paths, temp_binary, temp_subtype,\n",
    "        test_size=val_size_adjusted,\n",
    "        random_state=random_state,\n",
    "        stratify=temp_binary\n",
    "    )\n",
    "    \n",
    "    # Return requested split\n",
    "    if split == 'train':\n",
    "        print(f\"Dataset 1 (TRAIN - Original only): {len(train_paths)} images\")\n",
    "        print(f\"  Benign: {train_binary.count(0)}, Malignant: {train_binary.count(1)}\")\n",
    "        return train_paths, train_binary, train_subtype\n",
    "    elif split == 'val':\n",
    "        print(f\"Dataset 1 (VAL - Original only): {len(val_paths)} images\")\n",
    "        print(f\"  Benign: {val_binary.count(0)}, Malignant: {val_binary.count(1)}\")\n",
    "        return val_paths, val_binary, val_subtype\n",
    "    else:  # test\n",
    "        print(f\"Dataset 1 (TEST - Original only): {len(test_paths)} images\")\n",
    "        print(f\"  Benign: {test_binary.count(0)}, Malignant: {test_binary.count(1)}\")\n",
    "        return test_paths, test_binary, test_subtype\n",
    "\n",
    "\n",
    "def load_dataset2(split='Training'):\n",
    "    \"\"\"\n",
    "    Load Dataset 2 (Both binary and subtype labels).\n",
    "    \n",
    "    Args:\n",
    "        split: 'Training', 'Validation', or 'Testing'\n",
    "    \n",
    "    Returns:\n",
    "        image_paths, labels_binary, labels_subtype\n",
    "    \"\"\"\n",
    "    if split == 'Training':\n",
    "        base_path = DS2_TRAINING\n",
    "    elif split == 'Validation':\n",
    "        base_path = DS2_VALIDATION\n",
    "    else:\n",
    "        base_path = DS2_TESTING\n",
    "    \n",
    "\n",
    "    image_paths = []    return image_paths, labels_binary, labels_subtype\n",
    "\n",
    "    labels_binary = []    \n",
    "\n",
    "    labels_subtype = []    print(f\"  Total: {len(image_paths)} images\")\n",
    "\n",
    "        print(f\"Dataset 2 ({split}) loaded: {class_counts}\")\n",
    "\n",
    "    class_counts = {}    \n",
    "\n",
    "            class_counts[subtype_name] = len(subtype_images)\n",
    "\n",
    "    for subtype_idx, subtype_name in enumerate(DS2_CLASSES):        \n",
    "\n",
    "        subtype_path = os.path.join(base_path, subtype_name)        labels_subtype.extend([subtype_idx] * len(subtype_images))\n",
    "\n",
    "        subtype_images = get_image_files(subtype_path)        labels_binary.extend([binary_label] * len(subtype_images))\n",
    "\n",
    "                image_paths.extend(subtype_images)\n",
    "\n",
    "        # Determine binary label based on subtype        \n",
    "        binary_label = 1 if subtype_name in MALIGNANT_SUBTYPES else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46da46",
   "metadata": {},
   "source": [
    "## 5. Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size for the model\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Training transforms with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n",
    "    transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Transforms defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16412287",
   "metadata": {},
   "source": [
    "## 6. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2  # Adjust based on your system\n",
    "\n",
    "# Load Dataset 1 splits (ORIGINAL DATA ONLY - NO AUGMENTATION)\n",
    "print(\"Loading Dataset 1 (Original only - NO augmented data)...\")\n",
    "ds1_train_paths, ds1_train_binary, ds1_train_subtype = load_dataset1_split('train')\n",
    "ds1_val_paths, ds1_val_binary, ds1_val_subtype = load_dataset1_split('val')\n",
    "ds1_test_paths, ds1_test_binary, ds1_test_subtype = load_dataset1_split('test')\n",
    "\n",
    "# Load Dataset 2 splits (uses pre-split folders)\n",
    "print(\"\\nLoading Dataset 2 (Pre-split folders)...\")\n",
    "ds2_train_paths, ds2_train_binary, ds2_train_subtype = load_dataset2('Training')\n",
    "\n",
    "ds2_val_paths, ds2_val_binary, ds2_val_subtype = load_dataset2('Validation')ds2_test_paths, ds2_test_binary, ds2_test_subtype = load_dataset2('Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine DS1 and DS2 for each split (train/val/test)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINING DATASETS (NO DATA LEAKAGE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training set: DS1 train + DS2 train\n",
    "train_paths = ds1_train_paths + ds2_train_paths\n",
    "train_binary = ds1_train_binary + ds2_train_binary\n",
    "train_subtype = ds1_train_subtype + ds2_train_subtype\n",
    "\n",
    "print(f\"\\nTraining Set: {len(train_paths)} images\")\n",
    "print(f\"  - From DS1: {len(ds1_train_paths)} (original only, subtype=-1)\")\n",
    "print(f\"  - From DS2: {len(ds2_train_paths)} (with subtype labels)\")\n",
    "\n",
    "# Validation set: DS1 val + DS2 val\n",
    "val_paths = ds1_val_paths + ds2_val_paths\n",
    "val_binary = ds1_val_binary + ds2_val_binary\n",
    "val_subtype = ds1_val_subtype + ds2_val_subtype\n",
    "\n",
    "print(f\"\\nValidation Set: {len(val_paths)} images\")\n",
    "print(f\"  - From DS1: {len(ds1_val_paths)} (original only, subtype=-1)\")\n",
    "print(f\"  - From DS2: {len(ds2_val_paths)} (with subtype labels)\")\n",
    "\n",
    "# Test set: DS1 test + DS2 test (combined for overall evaluation)\n",
    "test_paths_combined = ds1_test_paths + ds2_test_paths\n",
    "test_binary_combined = ds1_test_binary + ds2_test_binary\n",
    "test_subtype_combined = ds1_test_subtype + ds2_test_subtype\n",
    "\n",
    "print(f\"\\nTest Set (Combined): {len(test_paths_combined)} images\")\n",
    "print(f\"  - From DS1: {len(ds1_test_paths)} (original only, subtype=-1)\")\n",
    "print(f\"  - From DS2: {len(ds2_test_paths)} (with subtype labels)\")\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = OralPathologyDataset(train_paths, train_binary, train_subtype, transform=train_transform)\n",
    "val_dataset = OralPathologyDataset(val_paths, val_binary, val_subtype, transform=val_transform)\n",
    "\n",
    "# Separate test sets for individual evaluation\n",
    "test_dataset_ds1 = OralPathologyDataset(ds1_test_paths, ds1_test_binary, ds1_test_subtype, transform=val_transform)\n",
    "test_dataset_ds2 = OralPathologyDataset(ds2_test_paths, ds2_test_binary, ds2_test_subtype, transform=val_transform)\n",
    "test_dataset_combined = OralPathologyDataset(test_paths_combined, test_binary_combined, test_subtype_combined, transform=val_transform)\n",
    "\n",
    "print(f\"\\n✓ All datasets created WITHOUT data leakage\")\n",
    "print(f\"✓ DS1 uses ONLY original images (no augmented)\")\n",
    "print(f\"✓ Train/Val/Test splits are completely separate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Separate test loaders for individual dataset evaluation\n",
    "test_loader_ds1 = DataLoader(\n",
    "    test_dataset_ds1, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader_ds2 = DataLoader(\n",
    "    test_dataset_ds2, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Combined test loader for overall evaluation\n",
    "test_loader_combined = DataLoader(\n",
    "    test_dataset_combined,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoader Summary:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Test DS1 batches: {len(test_loader_ds1)}\")\n",
    "print(f\"  Test DS2 batches: {len(test_loader_ds2)}\")\n",
    "print(f\"  Test Combined batches: {len(test_loader_combined)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a60515",
   "metadata": {},
   "source": [
    "## 7. Model Architecture (Y-Shape Dual Head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06327180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskOralClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Dual-Head Multi-Task Model for Oral Pathology Classification.\n",
    "    \n",
    "    Architecture:\n",
    "        - Shared Backbone: ResNet50 (pretrained)\n",
    "        - Head 1 (Binary): Malignant vs Benign\n",
    "        - Head 2 (Multi-class): Subtype classification\n",
    "    \n",
    "    Both heads are INDEPENDENT and trained in PARALLEL (Flat MTL).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_subtypes=7, backbone='resnet50', dropout=0.5):\n",
    "        super(MultiTaskOralClassifier, self).__init__()\n",
    "        \n",
    "        # Load pretrained backbone\n",
    "        if backbone == 'resnet50':\n",
    "            self.backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "            num_features = self.backbone.fc.in_features\n",
    "            # Remove the final classification layer\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        elif backbone == 'convnext_tiny':\n",
    "            self.backbone = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "            num_features = self.backbone.classifier[2].in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Head 1: Binary Classification (Malignant vs Benign)\n",
    "        self.head_binary = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(512, 2)  # 2 classes: Benign, Malignant\n",
    "        )\n",
    "        \n",
    "        # Head 2: Subtype Classification\n",
    "        self.head_subtype = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(512, num_subtypes)  # N classes\n",
    "        )\n",
    "        \n",
    "        print(f\"Model initialized with {backbone} backbone\")\n",
    "        print(f\"  - Feature size: {num_features}\")\n",
    "        print(f\"  - Head 1 (Binary): 2 classes\")\n",
    "        print(f\"  - Head 2 (Subtype): {num_subtypes} classes\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features using shared backbone\n",
    "        features = self.backbone(x)\n",
    "        features = self.dropout(features)\n",
    "        \n",
    "        # Pass through BOTH heads INDEPENDENTLY\n",
    "        out_binary = self.head_binary(features)\n",
    "        out_subtype = self.head_subtype(features)\n",
    "        \n",
    "        return out_binary, out_subtype\n",
    "    \n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze backbone weights for transfer learning.\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"Backbone frozen.\")\n",
    "    \n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Unfreeze backbone weights for fine-tuning.\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"Backbone unfrozen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04351ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "NUM_SUBTYPES = len(DS2_CLASSES)  # 7 classes\n",
    "\n",
    "model = MultiTaskOralClassifier(\n",
    "    num_subtypes=NUM_SUBTYPES,\n",
    "    backbone='resnet50',\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "# Print model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d46d0",
   "metadata": {},
   "source": [
    "## 8. Loss Functions (with Masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73673542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Combined loss for Multi-Task Learning.\n",
    "    \n",
    "    - Loss 1 (Binary): CrossEntropyLoss for all samples\n",
    "    - Loss 2 (Subtype): CrossEntropyLoss with ignore_index=-1\n",
    "      This ensures DS1 samples (with subtype=-1) don't contribute to Head 2 loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weight_binary=1.0, weight_subtype=1.0):\n",
    "        super(MultiTaskLoss, self).__init__()\n",
    "        \n",
    "        self.weight_binary = weight_binary\n",
    "        self.weight_subtype = weight_subtype\n",
    "        \n",
    "        # Loss for binary classification (applied to ALL samples)\n",
    "        self.criterion_binary = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Loss for subtype classification (IGNORES samples with label=-1)\n",
    "        # This is the CRITICAL \"Masking Trick\"\n",
    "        self.criterion_subtype = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    \n",
    "    def forward(self, pred_binary, pred_subtype, target_binary, target_subtype):\n",
    "        \"\"\"\n",
    "        Calculate combined loss.\n",
    "        \n",
    "        Args:\n",
    "            pred_binary: Predictions from Head 1 (N, 2)\n",
    "            pred_subtype: Predictions from Head 2 (N, num_subtypes)\n",
    "            target_binary: Binary labels (N,)\n",
    "            target_subtype: Subtype labels (N,), -1 for DS1 samples\n",
    "        \n",
    "        Returns:\n",
    "            total_loss, loss_binary, loss_subtype\n",
    "        \"\"\"\n",
    "        # Binary loss (all samples contribute)\n",
    "        loss_binary = self.criterion_binary(pred_binary, target_binary)\n",
    "        \n",
    "        # Subtype loss (only DS2 samples contribute, DS1 samples with -1 are ignored)\n",
    "        loss_subtype = self.criterion_subtype(pred_subtype, target_subtype)\n",
    "        \n",
    "        # Handle case when all samples are DS1 (no valid subtype labels)\n",
    "        if torch.isnan(loss_subtype):\n",
    "            loss_subtype = torch.tensor(0.0, device=pred_binary.device)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = (self.weight_binary * loss_binary) + (self.weight_subtype * loss_subtype)\n",
    "        \n",
    "        return total_loss, loss_binary, loss_subtype\n",
    "\n",
    "\n",
    "# Initialize loss function\n",
    "criterion = MultiTaskLoss(weight_binary=1.0, weight_subtype=1.0)\n",
    "print(\"Multi-Task Loss initialized with masking for subtype head.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd53b7e",
   "metadata": {},
   "source": [
    "## 9. Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "# Optimizer: AdamW\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler: Cosine Annealing\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCHS,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\")\n",
    "print(f\"Scheduler: CosineAnnealingLR (T_max={NUM_EPOCHS})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e02098",
   "metadata": {},
   "source": [
    "## 10. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss, avg_loss_binary, avg_loss_subtype, acc_binary, acc_subtype\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_loss_binary = 0.0\n",
    "    running_loss_subtype = 0.0\n",
    "    \n",
    "    all_preds_binary = []\n",
    "    all_targets_binary = []\n",
    "    all_preds_subtype = []\n",
    "    all_targets_subtype = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for images, targets_binary, targets_subtype in pbar:\n",
    "        images = images.to(device)\n",
    "        targets_binary = targets_binary.to(device)\n",
    "        targets_subtype = targets_subtype.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass - get predictions from BOTH heads\n",
    "        pred_binary, pred_subtype = model(images)\n",
    "        \n",
    "        # Calculate loss (with masking for subtype)\n",
    "        loss, loss_binary, loss_subtype = criterion(\n",
    "            pred_binary, pred_subtype, targets_binary, targets_subtype\n",
    "        )\n",
    "        \n",
    "        # Backward pass - updates shared backbone AND both heads\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        running_loss += loss.item()\n",
    "        running_loss_binary += loss_binary.item()\n",
    "        running_loss_subtype += loss_subtype.item() if not torch.isnan(loss_subtype) else 0\n",
    "        \n",
    "        # Track predictions for accuracy\n",
    "        preds_binary = torch.argmax(pred_binary, dim=1)\n",
    "        all_preds_binary.extend(preds_binary.cpu().numpy())\n",
    "        all_targets_binary.extend(targets_binary.cpu().numpy())\n",
    "        \n",
    "        # Only track subtype predictions for DS2 samples (where target != -1)\n",
    "        mask = targets_subtype != -1\n",
    "        if mask.sum() > 0:\n",
    "            preds_subtype = torch.argmax(pred_subtype[mask], dim=1)\n",
    "            all_preds_subtype.extend(preds_subtype.cpu().numpy())\n",
    "            all_targets_subtype.extend(targets_subtype[mask].cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate metrics\n",
    "    num_batches = len(train_loader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    avg_loss_binary = running_loss_binary / num_batches\n",
    "    avg_loss_subtype = running_loss_subtype / num_batches\n",
    "    \n",
    "    acc_binary = accuracy_score(all_targets_binary, all_preds_binary)\n",
    "    acc_subtype = accuracy_score(all_targets_subtype, all_preds_subtype) if all_targets_subtype else 0.0\n",
    "    \n",
    "    return avg_loss, avg_loss_binary, avg_loss_subtype, acc_binary, acc_subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model.\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss, acc_binary, acc_subtype\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    all_preds_binary = []\n",
    "    all_targets_binary = []\n",
    "    all_preds_subtype = []\n",
    "    all_targets_subtype = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets_binary, targets_subtype in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            targets_binary = targets_binary.to(device)\n",
    "            targets_subtype = targets_subtype.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_binary, pred_subtype = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss, _, _ = criterion(pred_binary, pred_subtype, targets_binary, targets_subtype)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Track predictions\n",
    "            preds_binary = torch.argmax(pred_binary, dim=1)\n",
    "            all_preds_binary.extend(preds_binary.cpu().numpy())\n",
    "            all_targets_binary.extend(targets_binary.cpu().numpy())\n",
    "            \n",
    "            # Track subtype predictions\n",
    "            mask = targets_subtype != -1\n",
    "            if mask.sum() > 0:\n",
    "                preds_subtype = torch.argmax(pred_subtype[mask], dim=1)\n",
    "                all_preds_subtype.extend(preds_subtype.cpu().numpy())\n",
    "                all_targets_subtype.extend(targets_subtype[mask].cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    acc_binary = accuracy_score(all_targets_binary, all_preds_binary)\n",
    "    acc_subtype = accuracy_score(all_targets_subtype, all_preds_subtype) if all_targets_subtype else 0.0\n",
    "    \n",
    "    return avg_loss, acc_binary, acc_subtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef11a1",
   "metadata": {},
   "source": [
    "## 11. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_loss_binary': [],\n",
    "    'train_loss_subtype': [],\n",
    "    'train_acc_binary': [],\n",
    "    'train_acc_subtype': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc_binary': [],\n",
    "    'val_acc_subtype': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = '/content/drive/MyDrive/dataset/best_model.pth'\n",
    "\n",
    "print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_loss_b, train_loss_s, train_acc_b, train_acc_s = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc_b, val_acc_s = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Log history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_loss_binary'].append(train_loss_b)\n",
    "    history['train_loss_subtype'].append(train_loss_s)\n",
    "    history['train_acc_binary'].append(train_acc_b)\n",
    "    history['train_acc_subtype'].append(train_acc_s)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc_binary'].append(val_acc_b)\n",
    "    history['val_acc_subtype'].append(val_acc_s)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f} (Binary: {train_loss_b:.4f}, Subtype: {train_loss_s:.4f})\")\n",
    "    print(f\"Train Acc:  Binary: {train_acc_b:.4f}, Subtype: {train_acc_s:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"Val Acc:    Binary: {val_acc_b:.4f}, Subtype: {val_acc_s:.4f}\")\n",
    "    print(f\"LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc_binary': val_acc_b,\n",
    "            'val_acc_subtype': val_acc_s,\n",
    "        }, best_model_path)\n",
    "        print(f\"✓ Best model saved! (val_loss: {val_loss:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416f6eb",
   "metadata": {},
   "source": [
    "## 12. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000abe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss plot\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(history['train_loss'], label='Train Total Loss', color='blue')\n",
    "ax1.plot(history['val_loss'], label='Val Loss', color='orange')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Total Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Individual losses\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(history['train_loss_binary'], label='Binary Loss', color='green')\n",
    "ax2.plot(history['train_loss_subtype'], label='Subtype Loss', color='red')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Train Loss by Head')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Binary accuracy\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(history['train_acc_binary'], label='Train', color='blue')\n",
    "ax3.plot(history['val_acc_binary'], label='Val', color='orange')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_title('Binary Head Accuracy (Head 1)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Subtype accuracy\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(history['train_acc_subtype'], label='Train', color='blue')\n",
    "ax4.plot(history['val_acc_subtype'], label='Val', color='orange')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "ax4.set_title('Subtype Head Accuracy (Head 2)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/dataset/training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4233a",
   "metadata": {},
   "source": [
    "## 13. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950dea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best val_loss: {checkpoint['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, dataset_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation.\n",
    "    \n",
    "    Returns predictions and targets for both heads.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds_binary = []\n",
    "    all_targets_binary = []\n",
    "    all_preds_subtype = []\n",
    "    all_targets_subtype = []\n",
    "    all_probs_binary = []\n",
    "    all_probs_subtype = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets_binary, targets_subtype in tqdm(test_loader, desc=f\"Evaluating {dataset_name}\"):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_binary, pred_subtype = model(images)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probs_binary = torch.softmax(pred_binary, dim=1)\n",
    "            probs_subtype = torch.softmax(pred_subtype, dim=1)\n",
    "            \n",
    "            # Get predictions\n",
    "            preds_binary = torch.argmax(pred_binary, dim=1)\n",
    "            preds_subtype = torch.argmax(pred_subtype, dim=1)\n",
    "            \n",
    "            # Store all predictions\n",
    "            all_preds_binary.extend(preds_binary.cpu().numpy())\n",
    "            all_targets_binary.extend(targets_binary.numpy())\n",
    "            all_probs_binary.extend(probs_binary.cpu().numpy())\n",
    "            \n",
    "            # Store subtype predictions (only for valid labels)\n",
    "            mask = targets_subtype != -1\n",
    "            if mask.sum() > 0:\n",
    "                all_preds_subtype.extend(preds_subtype[mask].cpu().numpy())\n",
    "                all_targets_subtype.extend(targets_subtype[mask].numpy())\n",
    "                all_probs_subtype.extend(probs_subtype[mask].cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'preds_binary': np.array(all_preds_binary),\n",
    "        'targets_binary': np.array(all_targets_binary),\n",
    "        'probs_binary': np.array(all_probs_binary),\n",
    "        'preds_subtype': np.array(all_preds_subtype),\n",
    "        'targets_subtype': np.array(all_targets_subtype),\n",
    "        'probs_subtype': np.array(all_probs_subtype) if all_probs_subtype else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on DS1 Test Set (Binary Head)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION ON DATASET 1 TEST SET (Binary Classification)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_ds1 = evaluate_model(model, test_loader_ds1, device, \"DS1\")\n",
    "\n",
    "# Binary metrics for DS1\n",
    "acc_binary_ds1 = accuracy_score(results_ds1['targets_binary'], results_ds1['preds_binary'])\n",
    "print(f\"\\nBinary Accuracy (DS1): {acc_binary_ds1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Binary - DS1):\")\n",
    "print(classification_report(\n",
    "    results_ds1['targets_binary'], \n",
    "    results_ds1['preds_binary'],\n",
    "    target_names=['Benign', 'Malignant']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01106361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on DS2 Test Set (Both Heads)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION ON DATASET 2 TEST SET (Both Classifications)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_ds2 = evaluate_model(model, test_loader_ds2, device, \"DS2\")\n",
    "\n",
    "# Binary metrics for DS2\n",
    "acc_binary_ds2 = accuracy_score(results_ds2['targets_binary'], results_ds2['preds_binary'])\n",
    "print(f\"\\nBinary Accuracy (DS2): {acc_binary_ds2:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Binary - DS2):\")\n",
    "print(classification_report(\n",
    "    results_ds2['targets_binary'], \n",
    "    results_ds2['preds_binary'],\n",
    "    target_names=['Benign', 'Malignant']\n",
    "))\n",
    "\n",
    "# Subtype metrics for DS2\n",
    "acc_subtype_ds2 = accuracy_score(results_ds2['targets_subtype'], results_ds2['preds_subtype'])\n",
    "print(f\"\\nSubtype Accuracy (DS2): {acc_subtype_ds2:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Subtype - DS2):\")\n",
    "print(classification_report(\n",
    "    results_ds2['targets_subtype'], \n",
    "    results_ds2['preds_subtype'],\n",
    "    target_names=DS2_CLASSES\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d28c3ab",
   "metadata": {},
   "source": [
    "## 14. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title, ax):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=classes, yticklabels=classes, ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# DS1 Binary\n",
    "plot_confusion_matrix(\n",
    "    results_ds1['targets_binary'], results_ds1['preds_binary'],\n",
    "    ['Benign', 'Malignant'], 'DS1 - Binary Classification', axes[0]\n",
    ")\n",
    "\n",
    "# DS2 Binary\n",
    "plot_confusion_matrix(\n",
    "    results_ds2['targets_binary'], results_ds2['preds_binary'],\n",
    "    ['Benign', 'Malignant'], 'DS2 - Binary Classification', axes[1]\n",
    ")\n",
    "\n",
    "# DS2 Subtype\n",
    "plot_confusion_matrix(\n",
    "    results_ds2['targets_subtype'], results_ds2['preds_subtype'],\n",
    "    DS2_CLASSES, 'DS2 - Subtype Classification', axes[2]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/dataset/confusion_matrices.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59c768",
   "metadata": {},
   "source": [
    "## 15. Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5557b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n📊 Model: Dual-Head Multi-Task Classifier (Flat MTL)\")\n",
    "print(f\"   Backbone: ResNet50 (pretrained)\")\n",
    "print(f\"   Head 1: Binary (Malignant/Benign)\")\n",
    "print(f\"   Head 2: Subtype ({len(DS2_CLASSES)} classes)\")\n",
    "\n",
    "print(\"\\n📈 Performance Metrics:\")\n",
    "print(\"\\n   Head 1 - Binary Classification:\")\n",
    "print(f\"   ├── DS1 Test Accuracy: {acc_binary_ds1:.4f} ({acc_binary_ds1*100:.2f}%)\")\n",
    "print(f\"   └── DS2 Test Accuracy: {acc_binary_ds2:.4f} ({acc_binary_ds2*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n   Head 2 - Subtype Classification:\")\n",
    "print(f\"   └── DS2 Test Accuracy: {acc_subtype_ds2:.4f} ({acc_subtype_ds2*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n📁 Saved Files:\")\n",
    "print(f\"   ├── Best Model: {best_model_path}\")\n",
    "print(f\"   ├── Training History: /content/drive/MyDrive/dataset/training_history.png\")\n",
    "print(f\"   └── Confusion Matrices: /content/drive/MyDrive/dataset/confusion_matrices.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d7e6c3",
   "metadata": {},
   "source": [
    "## 16. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, image_path, device):\n",
    "    \"\"\"\n",
    "    Make prediction on a single image.\n",
    "    \n",
    "    Returns both head predictions with confidence scores.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and transform image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = val_transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_binary, pred_subtype = model(image_tensor)\n",
    "        \n",
    "        # Get probabilities\n",
    "        probs_binary = torch.softmax(pred_binary, dim=1)[0]\n",
    "        probs_subtype = torch.softmax(pred_subtype, dim=1)[0]\n",
    "        \n",
    "        # Get predictions\n",
    "        pred_b = torch.argmax(probs_binary).item()\n",
    "        pred_s = torch.argmax(probs_subtype).item()\n",
    "    \n",
    "    binary_labels = ['Benign', 'Malignant']\n",
    "    \n",
    "    return {\n",
    "        'binary_prediction': binary_labels[pred_b],\n",
    "        'binary_confidence': probs_binary[pred_b].item(),\n",
    "        'subtype_prediction': DS2_CLASSES[pred_s],\n",
    "        'subtype_confidence': probs_subtype[pred_s].item(),\n",
    "        'all_subtype_probs': {cls: probs_subtype[i].item() for i, cls in enumerate(DS2_CLASSES)}\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage (uncomment and provide an image path)\n",
    "# test_image = '/content/drive/MyDrive/dataset/Dataset 2 /Testing/MC/sample.jpg'\n",
    "# result = predict_single_image(model, test_image, device)\n",
    "# print(f\"Binary: {result['binary_prediction']} ({result['binary_confidence']*100:.2f}%)\")\n",
    "# print(f\"Subtype: {result['subtype_prediction']} ({result['subtype_confidence']*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfd230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "def visualize_predictions(model, test_loader, device, num_samples=8):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on sample images.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch\n",
    "    images, targets_binary, targets_subtype = next(iter(test_loader))\n",
    "    images = images[:num_samples].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_binary, pred_subtype = model(images)\n",
    "        preds_b = torch.argmax(pred_binary, dim=1).cpu()\n",
    "        preds_s = torch.argmax(pred_subtype, dim=1).cpu()\n",
    "    \n",
    "    # Denormalize for visualization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    images_denorm = images.cpu() * std + mean\n",
    "    \n",
    "    binary_labels = ['Benign', 'Malignant']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        img = images_denorm[i].permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        true_b = binary_labels[targets_binary[i]]\n",
    "        pred_b = binary_labels[preds_b[i]]\n",
    "        true_s = DS2_CLASSES[targets_subtype[i]] if targets_subtype[i] != -1 else 'N/A'\n",
    "        pred_s = DS2_CLASSES[preds_s[i]]\n",
    "        \n",
    "        color = 'green' if preds_b[i] == targets_binary[i] else 'red'\n",
    "        \n",
    "        axes[i].set_title(f\"True: {true_b} / {true_s}\\nPred: {pred_b} / {pred_s}\", \n",
    "                          color=color, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/drive/MyDrive/dataset/prediction_samples.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, test_loader_ds2, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a62c09",
   "metadata": {},
   "source": [
    "## 17. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b86b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model with all metadata\n",
    "final_model_path = '/content/drive/MyDrive/dataset/final_model.pth'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'history': history,\n",
    "    'config': {\n",
    "        'num_subtypes': NUM_SUBTYPES,\n",
    "        'ds2_classes': DS2_CLASSES,\n",
    "        'malignant_subtypes': MALIGNANT_SUBTYPES,\n",
    "        'img_size': IMG_SIZE,\n",
    "        'backbone': 'resnet50'\n",
    "    },\n",
    "    'results': {\n",
    "        'ds1_binary_accuracy': acc_binary_ds1,\n",
    "        'ds2_binary_accuracy': acc_binary_ds2,\n",
    "        'ds2_subtype_accuracy': acc_subtype_ds2\n",
    "    }\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"Final model saved to: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac17b4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "### Key Points of Flat Multi-Task Learning:\n",
    "\n",
    "1. **No Dependency:** The model does NOT check if it's \"Malignant\" first before checking the \"Type.\"\n",
    "\n",
    "2. **Parallel Output:** The model looks at the image and **simultaneously** outputs two answers:\n",
    "   - Answer A: \"It looks Malignant/Benign\"\n",
    "   - Answer B: \"It looks like [subtype] type\"\n",
    "\n",
    "3. **Masking Trick:** Using `ignore_index=-1` in CrossEntropyLoss ensures that:\n",
    "   - DS1 samples contribute to Head 1 (Binary) training\n",
    "   - DS1 samples do NOT contribute to Head 2 (Subtype) training\n",
    "   - DS2 samples contribute to BOTH heads\n",
    "\n",
    "4. **Advantages:**\n",
    "   - Prevents error propagation from one head to another\n",
    "   - Shared backbone learns features useful for both tasks\n",
    "   - Both heads can be trained with different amounts of data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728c9ea",
   "metadata": {},
   "source": [
    "## Summary: Flat Multi-Task Learning Architecture\n",
    "\n",
    "**Key Points:**\n",
    "1. ✓ **No Hierarchical Dependency:** Both heads predict independently\n",
    "2. ✓ **Shared Backbone:** ResNet50 extracts features for both tasks\n",
    "3. ✓ **Masked Loss:** DS1 images don't contribute to Head 2's gradient\n",
    "4. ✓ **Parallel Training:** Both heads update simultaneously during backpropagation\n",
    "5. ✓ **Independent Evaluation:** Each head's performance measured separately\n",
    "\n",
    "**Architecture Flow:**\n",
    "```\n",
    "Image → ResNet50 → Features → ┬→ Head 1 (Binary) → Benign/Malignant\n",
    "                              └→ Head 2 (Subtype) → CaS/CoS/Gum/MC/OC/OLP/OT\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- No error propagation between heads\n",
    "- Simpler training compared to hierarchical models\n",
    "- Both tasks benefit from shared feature learning\n",
    "- Flexible: Can use predictions from either head independently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
